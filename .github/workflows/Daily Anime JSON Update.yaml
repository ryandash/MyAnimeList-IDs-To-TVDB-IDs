name: "Daily Anime JSON Update"

on:
  workflow_dispatch:
    inputs:
      manual_total_pages:
        description: "Override total number of pages (leave empty to auto-detect)"
        required: false
        default: ""
  schedule:
    - cron: "0 7 * * *"
  push:
    branches:
      - main
    paths:
      - "requirements.txt"

permissions:
  contents: write

concurrency:
  group: "anime-json-update"
  cancel-in-progress: true

jobs:  
  determine_total_pages:
    name: Determine Total Pages
    runs-on: ubuntu-latest
    outputs:
      pages: ${{ steps.generate_pages.outputs.pages }}
    steps:
      - name: Checkout Repository
        uses: actions/checkout@v5
        with:
          fetch-depth: 1
      
      - name: Cache pip + Playwright
        id: cache-deps
        uses: actions/cache@v4
        with:
          path: |
            ~/.cache/pip
            ~/.cache/ms-playwright
          key: deps-${{ hashFiles('requirements.txt') }}
          restore-keys: deps-

      - name: Install Python dependencies
        run: |
          pip install --upgrade pip
          pip install -r requirements.txt
          python -m playwright install --with-deps chromium

      - name: Decide Total Pages
        id: set_pages
        run: |
          if [ -n "${{ github.event.inputs.manual_total_pages }}" ]; then
            total="${{ github.event.inputs.manual_total_pages }}"
            echo "Using manual override: $total pages"
          else
            total=$(python get_total_pages.py | grep -oP '\d+')
            echo "Detected: $total pages"
          fi
          echo "total=${total}" >> $GITHUB_OUTPUT
      
      - name: Generate Page List
        id: generate_pages
        run: |
          total=${{ steps.set_pages.outputs.total }}
          total=${total:-1}
          pages=$(seq 1 $total | jq -R . | jq -s .)
          echo "pages<<EOF" >> $GITHUB_OUTPUT
          echo "${pages}" >> $GITHUB_OUTPUT
          echo "EOF" >> $GITHUB_OUTPUT

  scrape_pages:
    needs: determine_total_pages
    runs-on: ubuntu-latest
    strategy:
      max-parallel: 10
      matrix:
        page: ${{ fromJson(needs.determine_total_pages.outputs.pages) }}
    steps:
      - name: Checkout Repository
        uses: actions/checkout@v5
        with:
          fetch-depth: 1

      - name: Cache pip + Playwright
        id: cache-deps
        uses: actions/cache@v4
        with:
          path: |
            ~/.cache/pip
            ~/.cache/ms-playwright
          key: deps-${{ hashFiles('requirements.txt') }}
          restore-keys: deps-
      
      - name: Install Python dependencies
        run: |
          pip install --upgrade pip
          pip install -r requirements.txt
          python -m playwright install --with-deps chromium

      - name: Scrape & Process page
        run: |
          python thetvdb_scraper.py --page ${{ matrix.page }} --delete-folder
          python mal_mapper.py
          python split_json.py

      - name: Upload page outputs
        uses: actions/upload-artifact@v4
        with:
          name: page-${{ matrix.page }}
          path: |
            api/
            anime_data/
            mapped-tvdb-ids.json
            unmapped-tvdb-ids.json
          retention-days: 1

  combine_and_commit:
    name: Combine FILES & Commit
    needs: scrape_pages
    runs-on: ubuntu-latest
    steps:
      - name: Checkout Repository
        uses: actions/checkout@v5
        with:
          fetch-depth: 0
          persist-credentials: true

      - name: Cache pip + Playwright
        id: cache-deps
        uses: actions/cache@v4
        with:
          path: |
            ~/.cache/pip
            ~/.cache/ms-playwright
          key: deps-${{ hashFiles('requirements.txt') }}
          restore-keys: deps-

      - name: Install Python dependencies
        run: |
          pip install --upgrade pip
          pip install -r requirements.txt
          python -m playwright install --with-deps chromium

      - name: Download all artifacts
        uses: actions/download-artifact@v5
        with:
          path: artifacts/

      - name: Merge JSON files
        run: python merge_files.py --input-dir artifacts

      - name: Count mapped/unmapped
        id: counts
        run: |
          mapped=$(jq length mapped-tvdb-ids.json)
          unmapped=$(jq length unmapped-tvdb-ids.json)
          echo "mapped=$mapped" >> $GITHUB_OUTPUT
          echo "unmapped=$unmapped" >> $GITHUB_OUTPUT

      - name: Update README with counts
        run: |
          mapped=${{ steps.counts.outputs.mapped }}
          unmapped=${{ steps.counts.outputs.unmapped }}

          # Remove old section if it exists
          sed -i '/<!---counts-start--->/,/<!---counts-end--->/d' README.md

          # Append updated section
          {
            echo '<!---counts-start--->'
            echo "### TVDB → MAL Mapping Stats"
            echo ""
            echo "- ✅ Mapped IDs: **$mapped**"
            echo "- ❌ Unmapped IDs: **$unmapped**"
            echo '<!---counts-end--->'
          } >> README.md

      - name: Delete artifacts folder
        run: |
          rm -rf artifacts/

      - name: Commit Changes if Needed
        shell: bash
        run: |
          git config --local user.email "41898282+github-actions[bot]@users.noreply.github.com"
          git config --local user.name "GitHub Actions Bot"
          git add .

          if [ -n "$(git diff --cached)" ]; then
            date=$(date +%F)
            time=$(date +%T)
            git commit -m "Update JSON at $date $time"

            git fetch origin main
            git rebase origin/main || {
              git rebase --abort
              git merge -X ours origin/main
            }

            git push origin HEAD:main
            echo "JSON updated and changes pushed."
          else
            echo "No changes detected, skipping commit."
          fi
